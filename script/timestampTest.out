vehicle timestamp 0.2 seconds #####################################
19/01/27 14:07:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 14:07:08 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master en4119507l.cidse.dhcp.asu.edu:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to en4119507l.cidse.dhcp.asu.edu/10.218.106.186:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: en4119507l.cidse.dhcp.asu.edu/10.218.106.186:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/01/27 14:07:28 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master en4119507l.cidse.dhcp.asu.edu:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to en4119507l.cidse.dhcp.asu.edu/10.218.106.186:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: en4119507l.cidse.dhcp.asu.edu/10.218.106.186:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/01/27 14:07:48 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master en4119507l.cidse.dhcp.asu.edu:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to en4119507l.cidse.dhcp.asu.edu/10.218.106.186:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: en4119507l.cidse.dhcp.asu.edu/10.218.106.186:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
19/01/27 14:08:08 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.
19/01/27 14:08:08 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.
19/01/27 14:08:08 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master
19/01/27 14:08:08 ERROR SparkContext: Error initializing SparkContext.
java.lang.IllegalArgumentException: requirement failed: Can only call getServletHandlers on a running MetricsSystem
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.metrics.MetricsSystem.getServletHandlers(MetricsSystem.scala:91)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:515)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at com.zishanfu.vistrips.App.main(App.java:31)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Exception in thread "main" java.lang.IllegalArgumentException: requirement failed: Can only call getServletHandlers on a running MetricsSystem
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.metrics.MetricsSystem.getServletHandlers(MetricsSystem.scala:91)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:515)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at com.zishanfu.vistrips.App.main(App.java:31)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
10.5 G  /vistrips/reports_0
9.2 G  /vistrips/reports_1
en4119509l.cidse.dhcp.asu.edu: no org.apache.spark.deploy.worker.Worker to stop
en4119508l.cidse.dhcp.asu.edu: no org.apache.spark.deploy.worker.Worker to stop
en4119507l.cidse.dhcp.asu.edu: no org.apache.spark.deploy.worker.Worker to stop
en4119510l.cidse.dhcp.asu.edu: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
19/01/27 14:09:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 14:09:51 WARN App: Total: 100000, timestamp: 0.2, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 14:09:51 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 14:10:24 WARN GenerationImpl: Finished OSM graph construction! Time: 32 . Processing graphhopper ...
19/01/27 14:10:24 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 14:10:24 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 14:15:11 WARN GenerationImpl: Finished Generation! Time: 286 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_140952
19/01/27 14:15:33 WARN JmapConsole: Road Network Construction! Time: 22 seconds
19/01/27 14:15:33 WARN TrafficModelPanel: Simulation begin...
19/01/27 14:15:34 WARN TaskSetManager: Stage 13 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:15:37 WARN TaskSetManager: Stage 14 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:15:40 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 14:15:40 WARN TaskSetManager: Stage 15 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:15:42 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 14:15:42 WARN TaskSetManager: Stage 16 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:15:45 WARN TaskSetManager: Stage 17 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:15:48 WARN TrafficModelPanel: Before Write File! Time: 14 seconds
19/01/27 14:15:48 WARN TaskSetManager: Stage 18 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:54:52 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 2344 seconds
19/01/27 14:54:52 WARN TaskSetManager: Stage 20 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:54:55 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 14:54:55 WARN TaskSetManager: Stage 21 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:54:57 WARN TaskSetManager: Stage 22 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 14:55:00 WARN TrafficModelPanel: Before Write File! Time: 2366 seconds
19/01/27 14:55:00 WARN TaskSetManager: Stage 23 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 15:00:47 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 347 seconds
52.1 G  /vistrips/reports_0
45.6 G  /vistrips/reports_1
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
19/01/27 15:02:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 15:02:30 WARN App: Total: 100000, timestamp: 0.2, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 15:02:30 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 15:02:52 WARN GenerationImpl: Finished OSM graph construction! Time: 22 . Processing graphhopper ...
19/01/27 15:02:53 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 15:02:53 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 15:07:39 WARN GenerationImpl: Finished Generation! Time: 286 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_150230
19/01/27 15:08:04 WARN JmapConsole: Road Network Construction! Time: 24 seconds
19/01/27 15:08:04 WARN TrafficModelPanel: Simulation begin...
19/01/27 15:08:04 WARN TaskSetManager: Stage 13 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:08:07 WARN TaskSetManager: Stage 14 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:08:10 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 15:08:10 WARN TaskSetManager: Stage 15 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:08:12 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 15:08:12 WARN TaskSetManager: Stage 16 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:08:15 WARN TaskSetManager: Stage 17 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:08:17 WARN TrafficModelPanel: Before Write File! Time: 13 seconds
19/01/27 15:08:17 WARN TaskSetManager: Stage 18 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:28:53 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 1235 seconds
19/01/27 15:28:53 WARN TaskSetManager: Stage 20 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:28:56 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 15:28:56 WARN TaskSetManager: Stage 21 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:28:58 WARN TaskSetManager: Stage 22 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:29:01 WARN TrafficModelPanel: Before Write File! Time: 1256 seconds
19/01/27 15:29:01 WARN TaskSetManager: Stage 23 contains a task of very large size (136 KB). The maximum recommended task size is 100 KB.
19/01/27 15:34:14 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 313 seconds
57.5 G  /vistrips/reports_0
44.0 G  /vistrips/reports_1
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
vehicle timestamp 0.4 seconds #####################################
19/01/27 15:36:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 15:36:01 WARN App: Total: 100000, timestamp: 0.4, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 15:36:01 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 15:36:27 WARN GenerationImpl: Finished OSM graph construction! Time: 25 . Processing graphhopper ...
19/01/27 15:36:27 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 15:36:27 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 15:41:12 WARN GenerationImpl: Finished Generation! Time: 285 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_153601
19/01/27 15:41:34 WARN JmapConsole: Road Network Construction! Time: 21 seconds
19/01/27 15:41:34 WARN TrafficModelPanel: Simulation begin...
19/01/27 15:41:35 WARN TaskSetManager: Stage 13 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:41:38 WARN TaskSetManager: Stage 14 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:41:41 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 15:41:41 WARN TaskSetManager: Stage 15 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:41:43 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 15:41:43 WARN TaskSetManager: Stage 16 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:41:46 WARN TaskSetManager: Stage 17 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:41:48 WARN TrafficModelPanel: Before Write File! Time: 14 seconds
19/01/27 15:41:48 WARN TaskSetManager: Stage 18 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:51:40 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 591 seconds
19/01/27 15:51:40 WARN TaskSetManager: Stage 20 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:51:42 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 15:51:42 WARN TaskSetManager: Stage 21 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:51:45 WARN TaskSetManager: Stage 22 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:51:47 WARN TrafficModelPanel: Before Write File! Time: 612 seconds
19/01/27 15:51:47 WARN TaskSetManager: Stage 23 contains a task of very large size (139 KB). The maximum recommended task size is 100 KB.
19/01/27 15:55:12 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 204 seconds
26.5 G  /vistrips/reports_0
22.7 G  /vistrips/reports_1
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
19/01/27 15:56:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 15:57:00 WARN App: Total: 100000, timestamp: 0.4, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 15:57:00 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 15:57:18 WARN GenerationImpl: Finished OSM graph construction! Time: 18 . Processing graphhopper ...
19/01/27 15:57:19 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 15:57:19 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 16:02:03 WARN GenerationImpl: Finished Generation! Time: 284 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_155700
19/01/27 16:02:26 WARN JmapConsole: Road Network Construction! Time: 23 seconds
19/01/27 16:02:26 WARN TrafficModelPanel: Simulation begin...
19/01/27 16:02:26 WARN TaskSetManager: Stage 13 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:02:29 WARN TaskSetManager: Stage 14 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:02:32 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 16:02:32 WARN TaskSetManager: Stage 15 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:02:35 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 16:02:35 WARN TaskSetManager: Stage 16 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:02:37 WARN TaskSetManager: Stage 17 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:02:40 WARN TrafficModelPanel: Before Write File! Time: 13 seconds
19/01/27 16:02:40 WARN TaskSetManager: Stage 18 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:09:56 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 435 seconds
19/01/27 16:09:56 WARN TaskSetManager: Stage 20 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:09:58 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 16:09:58 WARN TaskSetManager: Stage 21 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:10:00 WARN TaskSetManager: Stage 22 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:10:03 WARN TrafficModelPanel: Before Write File! Time: 456 seconds
19/01/27 16:10:03 WARN TaskSetManager: Stage 23 contains a task of very large size (157 KB). The maximum recommended task size is 100 KB.
19/01/27 16:13:29 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 206 seconds
28.6 G  /vistrips/reports_0
23.0 G  /vistrips/reports_1
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
19/01/27 16:15:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 16:15:22 WARN App: Total: 100000, timestamp: 0.4, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 16:15:22 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 16:15:49 WARN GenerationImpl: Finished OSM graph construction! Time: 27 . Processing graphhopper ...
19/01/27 16:15:49 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 16:15:49 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 16:20:38 WARN GenerationImpl: Finished Generation! Time: 289 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_161522
19/01/27 16:21:01 WARN JmapConsole: Road Network Construction! Time: 23 seconds
19/01/27 16:21:01 WARN TrafficModelPanel: Simulation begin...
19/01/27 16:21:02 WARN TaskSetManager: Stage 13 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:21:05 WARN TaskSetManager: Stage 14 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:21:08 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 16:21:08 WARN TaskSetManager: Stage 15 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:21:10 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 16:21:10 WARN TaskSetManager: Stage 16 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:21:12 WARN TaskSetManager: Stage 17 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:21:15 WARN TrafficModelPanel: Before Write File! Time: 13 seconds
19/01/27 16:21:15 WARN TaskSetManager: Stage 18 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:35:54 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 879 seconds
19/01/27 16:35:54 WARN TaskSetManager: Stage 20 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:35:57 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 16:35:57 WARN TaskSetManager: Stage 21 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:35:59 WARN TaskSetManager: Stage 22 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:36:02 WARN TrafficModelPanel: Before Write File! Time: 900 seconds
19/01/27 16:36:02 WARN TaskSetManager: Stage 23 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 16:39:11 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 189 seconds
28.0 G  /vistrips/reports_0
21.5 G  /vistrips/reports_1
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
vehicle timestamp 0.6 seconds #####################################
19/01/27 16:40:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 16:40:59 WARN App: Total: 100000, timestamp: 0.6, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 16:40:59 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 16:41:17 WARN GenerationImpl: Finished OSM graph construction! Time: 18 . Processing graphhopper ...
19/01/27 16:41:17 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 16:41:17 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 16:46:00 WARN GenerationImpl: Finished Generation! Time: 283 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_164059
19/01/27 16:46:23 WARN JmapConsole: Road Network Construction! Time: 23 seconds
19/01/27 16:46:23 WARN TrafficModelPanel: Simulation begin...
19/01/27 16:46:23 WARN TaskSetManager: Stage 13 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 16:46:27 WARN TaskSetManager: Stage 14 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 16:46:29 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 16:46:29 WARN TaskSetManager: Stage 15 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 16:46:32 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 16:46:32 WARN TaskSetManager: Stage 16 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 16:46:34 WARN TaskSetManager: Stage 17 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 16:46:37 WARN TrafficModelPanel: Before Write File! Time: 13 seconds
19/01/27 16:46:37 WARN TaskSetManager: Stage 18 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 16:59:58 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 800 seconds
19/01/27 16:59:58 WARN TaskSetManager: Stage 20 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:00:00 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 17:00:00 WARN TaskSetManager: Stage 21 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:00:03 WARN TaskSetManager: Stage 22 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:00:05 WARN TrafficModelPanel: Before Write File! Time: 821 seconds
19/01/27 17:00:05 WARN TaskSetManager: Stage 23 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:02:38 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 153 seconds
17.6 G  /vistrips/reports_0
14.7 G  /vistrips/reports_1
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
19/01/27 17:04:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 17:04:27 WARN App: Total: 100000, timestamp: 0.6, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 17:04:27 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 17:04:51 WARN GenerationImpl: Finished OSM graph construction! Time: 24 . Processing graphhopper ...
19/01/27 17:04:52 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 17:04:52 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 17:09:39 WARN GenerationImpl: Finished Generation! Time: 287 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_170427
19/01/27 17:10:02 WARN JmapConsole: Road Network Construction! Time: 23 seconds
19/01/27 17:10:02 WARN TrafficModelPanel: Simulation begin...
19/01/27 17:10:02 WARN TaskSetManager: Stage 13 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:10:05 WARN TaskSetManager: Stage 14 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:10:08 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 17:10:08 WARN TaskSetManager: Stage 15 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:10:10 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 17:10:10 WARN TaskSetManager: Stage 16 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:10:13 WARN TaskSetManager: Stage 17 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:10:15 WARN TrafficModelPanel: Before Write File! Time: 13 seconds
19/01/27 17:10:15 WARN TaskSetManager: Stage 18 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:21:09 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 653 seconds
19/01/27 17:21:09 WARN TaskSetManager: Stage 20 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:21:11 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 17:21:11 WARN TaskSetManager: Stage 21 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:21:14 WARN TaskSetManager: Stage 22 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:21:16 WARN TrafficModelPanel: Before Write File! Time: 674 seconds
19/01/27 17:21:16 WARN TaskSetManager: Stage 23 contains a task of very large size (152 KB). The maximum recommended task size is 100 KB.
19/01/27 17:23:47 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 151 seconds
16.2 G  /vistrips/reports_0
14.9 G  /vistrips/reports_1
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
19/01/27 17:25:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 17:25:35 WARN App: Total: 100000, timestamp: 0.6, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 17:25:35 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 17:25:53 WARN GenerationImpl: Finished OSM graph construction! Time: 18 . Processing graphhopper ...
19/01/27 17:25:53 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 17:25:53 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 17:30:42 WARN GenerationImpl: Finished Generation! Time: 288 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_172535
19/01/27 17:31:05 WARN JmapConsole: Road Network Construction! Time: 23 seconds
19/01/27 17:31:05 WARN TrafficModelPanel: Simulation begin...
19/01/27 17:31:05 WARN TaskSetManager: Stage 13 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:31:08 WARN TaskSetManager: Stage 14 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:31:11 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 17:31:11 WARN TaskSetManager: Stage 15 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:31:13 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 17:31:13 WARN TaskSetManager: Stage 16 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:31:16 WARN TaskSetManager: Stage 17 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:31:18 WARN TrafficModelPanel: Before Write File! Time: 13 seconds
19/01/27 17:31:18 WARN TaskSetManager: Stage 18 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:44:51 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 812 seconds
19/01/27 17:44:51 WARN TaskSetManager: Stage 20 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:44:54 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 17:44:54 WARN TaskSetManager: Stage 21 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:44:56 WARN TaskSetManager: Stage 22 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:44:59 WARN TrafficModelPanel: Before Write File! Time: 833 seconds
19/01/27 17:44:59 WARN TaskSetManager: Stage 23 contains a task of very large size (148 KB). The maximum recommended task size is 100 KB.
19/01/27 17:47:35 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 156 seconds
18.1 G  /vistrips/reports_0
14.5 G  /vistrips/reports_1
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
vehicle timestamp 0.8 seconds #####################################
19/01/27 17:49:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/27 17:49:22 WARN App: Total: 100000, timestamp: 0.8, simulation time: 10, partition time: 5, partition used: 1000
19/01/27 17:49:22 WARN GenerationImpl: Processing OSM data in GraphX
19/01/27 17:49:46 WARN GenerationImpl: Finished OSM graph construction! Time: 23 . Processing graphhopper ...
19/01/27 17:49:46 WARN GenerationImpl: Finished graphhopper construction. Time: 0.
19/01/27 17:49:46 WARN GenerationImpl: Begin generate 100000 trips.
19/01/27 17:54:32 WARN GenerationImpl: Finished Generation! Time: 286 seconds
hdfs://en4119507l.cidse.dhcp.asu.edu:54310/vistrips/20190127_174922
19/01/27 17:54:57 WARN JmapConsole: Road Network Construction! Time: 24 seconds
19/01/27 17:54:57 WARN TrafficModelPanel: Simulation begin...
19/01/27 17:54:57 WARN TaskSetManager: Stage 13 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 17:55:01 WARN TaskSetManager: Stage 14 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 17:55:03 WARN TrafficModelPanel: Partition iteration begin...
19/01/27 17:55:03 WARN TaskSetManager: Stage 15 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 17:55:06 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 17:55:06 WARN TaskSetManager: Stage 16 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 17:55:09 WARN TaskSetManager: Stage 17 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 17:55:11 WARN TrafficModelPanel: Before Write File! Time: 14 seconds
19/01/27 17:55:11 WARN TaskSetManager: Stage 18 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 18:02:04 WARN TrafficModelPanel: Finished Partition 0 Simulation! Time: 412 seconds
19/01/27 18:02:04 WARN TaskSetManager: Stage 20 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 18:02:07 WARN TrafficModelPanel: Finished redefine linestring coordinates and repartition...shuffledVehicles 100000
19/01/27 18:02:07 WARN TaskSetManager: Stage 21 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 18:02:09 WARN TaskSetManager: Stage 22 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 18:02:11 WARN TrafficModelPanel: Before Write File! Time: 434 seconds
19/01/27 18:02:12 WARN TaskSetManager: Stage 23 contains a task of very large size (150 KB). The maximum recommended task size is 100 KB.
19/01/27 18:04:17 WARN TrafficModelPanel: Finished Partition 1 Simulation! Time: 125 seconds
du: failure to login
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
failed to launch: nice -n 0 /hdd2/code/spark-2.3.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master --host en4119507l.cidse.dhcp.asu.edu --port 7077 --webui-port 8080
  
  	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:856)
  	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
  	at java.security.AccessController.doPrivileged(Native Method)
  	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
  	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
  	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:797)
  	... 10 more
full log in /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:135)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1057)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1143)
	at org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:50)
	at org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)
	at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
du: failure to login
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
failed to launch: nice -n 0 /hdd2/code/spark-2.3.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master --host en4119507l.cidse.dhcp.asu.edu --port 7077 --webui-port 8080
  
  	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:856)
  	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
  	at java.security.AccessController.doPrivileged(Native Method)
  	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
  	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
  	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:797)
  	... 10 more
full log in /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:135)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1057)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1143)
	at org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:50)
	at org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)
	at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
du: failure to login
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
failed to launch: nice -n 0 /hdd2/code/spark-2.3.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master --host en4119507l.cidse.dhcp.asu.edu --port 7077 --webui-port 8080
  
  	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:856)
  	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
  	at java.security.AccessController.doPrivileged(Native Method)
  	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
  	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
  	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:797)
  	... 10 more
full log in /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
vehicle timestamp 1 seconds #####################################
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:135)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1057)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1143)
	at org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:50)
	at org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)
	at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
du: failure to login
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
failed to launch: nice -n 0 /hdd2/code/spark-2.3.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master --host en4119507l.cidse.dhcp.asu.edu --port 7077 --webui-port 8080
  
  	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:856)
  	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
  	at java.security.AccessController.doPrivileged(Native Method)
  	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
  	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
  	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:797)
  	... 10 more
full log in /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:135)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1057)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1143)
	at org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:50)
	at org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)
	at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
du: failure to login
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
failed to launch: nice -n 0 /hdd2/code/spark-2.3.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master --host en4119507l.cidse.dhcp.asu.edu --port 7077 --webui-port 8080
  
  	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:856)
  	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
  	at java.security.AccessController.doPrivileged(Native Method)
  	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
  	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
  	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:797)
  	... 10 more
full log in /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
Exception in thread "main" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local
	at org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)
	at org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:135)
	at org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)
	at org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1057)
	at org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1143)
	at org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:50)
	at org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)
	at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
du: failure to login
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
failed to launch: nice -n 0 /hdd2/code/spark-2.3.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master --host en4119507l.cidse.dhcp.asu.edu --port 7077 --webui-port 8080
  
  	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:856)
  	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
  	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
  	at java.security.AccessController.doPrivileged(Native Method)
  	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
  	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
  	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:797)
  	... 10 more
full log in /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-ASUAD\zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119507l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119509l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119508l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
en4119510l.cidse.dhcp.asu.edu: No user exists for uid 1940958126
