Spark partitionNumTest 4500 #####################################
19/04/10 10:07:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/04/10 10:07:21 WARN GeoSparkSim: 
P1: 33.48998, -112.10964
P2: 33.38827, -111.79722
Total: 100000
Steps: 600
Timestep: 1.0
Generation Type: DSO
Repartition Time: 120
Partition: 4500
Output: hdfs://en4119507l.cidse.dhcp.asu.edu:54310

19/04/10 10:08:37 WARN TaskSetManager: Stage 22 contains a task of very large size (21555 KB). The maximum recommended task size is 100 KB.
19/04/10 10:08:48 WARN GeoSparkSim: Read: edge: 240011, signals: 4392, intersects: 24218, vehicles: 100000
19/04/10 10:26:44 WARN Microscopic$: Repartition Time: 272.244
19/04/10 10:26:44 WARN GeoSparkSim: Finished Simulation: 1075
19/04/10 10:26:58 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.
19/04/10 10:27:01 ERROR GeoSparkSim: Because the number of vehicle is larger than 5000 or the area is larger than 800,0000, GeoSparkSim will not show the traffic visualization! Please check output in hdfs://en4119507l.cidse.dhcp.asu.edu:54310/geosparksim
12.9 M  /geosparksim/reports0
1.5 G  /geosparksim/reports1
1.5 G  /geosparksim/reports2
1.5 G  /geosparksim/reports3
1.5 G  /geosparksim/reports4
1.5 G  /geosparksim/reports5
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
19/04/10 10:29:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/04/10 10:29:17 WARN GeoSparkSim: 
P1: 33.48998, -112.10964
P2: 33.38827, -111.79722
Total: 100000
Steps: 600
Timestep: 1.0
Generation Type: DSO
Repartition Time: 120
Partition: 4500
Output: hdfs://en4119507l.cidse.dhcp.asu.edu:54310

19/04/10 10:31:07 WARN TaskSetManager: Stage 22 contains a task of very large size (21641 KB). The maximum recommended task size is 100 KB.
19/04/10 10:31:24 WARN GeoSparkSim: Read: edge: 240011, signals: 4392, intersects: 24218, vehicles: 100000
19/04/10 10:44:49 WARN Microscopic$: Repartition Time: 93.625
19/04/10 10:44:49 WARN GeoSparkSim: Finished Simulation: 805
19/04/10 10:45:04 ERROR GeoSparkSim: Because the number of vehicle is larger than 5000 or the area is larger than 800,0000, GeoSparkSim will not show the traffic visualization! Please check output in hdfs://en4119507l.cidse.dhcp.asu.edu:54310/geosparksim
12.8 M  /geosparksim/reports0
1.5 G  /geosparksim/reports1
1.5 G  /geosparksim/reports2
1.5 G  /geosparksim/reports3
1.5 G  /geosparksim/reports4
1.5 G  /geosparksim/reports5
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
19/04/10 10:47:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/04/10 10:47:20 WARN GeoSparkSim: 
P1: 33.48998, -112.10964
P2: 33.38827, -111.79722
Total: 100000
Steps: 600
Timestep: 1.0
Generation Type: DSO
Repartition Time: 120
Partition: 4500
Output: hdfs://en4119507l.cidse.dhcp.asu.edu:54310

19/04/10 10:49:07 WARN TaskSetManager: Stage 22 contains a task of very large size (21846 KB). The maximum recommended task size is 100 KB.
19/04/10 10:49:20 WARN GeoSparkSim: Read: edge: 240011, signals: 4392, intersects: 24218, vehicles: 100000
19/04/10 11:02:44 WARN Microscopic$: Repartition Time: 87.491
19/04/10 11:02:44 WARN GeoSparkSim: Finished Simulation: 804
19/04/10 11:02:57 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.
19/04/10 11:03:03 ERROR GeoSparkSim: Because the number of vehicle is larger than 5000 or the area is larger than 800,0000, GeoSparkSim will not show the traffic visualization! Please check output in hdfs://en4119507l.cidse.dhcp.asu.edu:54310/geosparksim
12.9 M  /geosparksim/reports0
1.5 G  /geosparksim/reports1
1.5 G  /geosparksim/reports2
1.5 G  /geosparksim/reports3
1.5 G  /geosparksim/reports4
1.5 G  /geosparksim/reports5
en4119508l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119509l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119507l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
en4119510l.cidse.dhcp.asu.edu: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.master.Master-1-en4119507l.out
en4119508l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119508l.out
en4119509l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119509l.out
en4119507l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119507l.out
en4119510l.cidse.dhcp.asu.edu: starting org.apache.spark.deploy.worker.Worker, logging to /hdd2/code/spark-2.3.2-bin-hadoop2.6/logs/spark-zishanfu-org.apache.spark.deploy.worker.Worker-1-en4119510l.out
